{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60fcaff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from graph.ipynb\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import Ipynb_importer\n",
    "from graph import *\n",
    "import graph as og\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44c7a771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_for_OpenNE(filename, weighted=False):\n",
    "    G = og.Graph()\n",
    "    print(\"Loading training graph for learning embedding...\")\n",
    "    G.read_edgelist(filename=filename, weighted=weighted)\n",
    "    print(\"Graph Loaded...\")\n",
    "    return G\n",
    "\n",
    "def split_train_test_graph(input_edgelist, seed, testing_ratio=0.1, weighted=False):\n",
    "    \n",
    "    if (weighted):\n",
    "        G = nx.read_weighted_edgelist(input_edgelist)\n",
    "    else:\n",
    "        G = nx.read_edgelist(input_edgelist)\n",
    "    node_num1, edge_num1 = len(G.nodes), len(G.edges)\n",
    "    print('Original Graph: nodes:', node_num1, 'edges:', edge_num1)\n",
    "    testing_edges_num = int(len(G.edges) * testing_ratio)\n",
    "    random.seed(seed)\n",
    "    testing_pos_edges = random.sample(G.edges, testing_edges_num)\n",
    "    G_train = copy.deepcopy(G)\n",
    "    for edge in testing_pos_edges:\n",
    "        node_u, node_v = edge\n",
    "        if (G_train.degree(node_u) > 1 and G_train.degree(node_v) > 1):\n",
    "            G_train.remove_edge(node_u, node_v)\n",
    "\n",
    "    G_train.remove_nodes_from(nx.isolates(G_train))\n",
    "    node_num2, edge_num2 = len(G_train.nodes), len(G_train.edges)\n",
    "    assert node_num1 == node_num2\n",
    "    train_graph_filename = 'graph_train.edgelist'\n",
    "    if weighted:\n",
    "        nx.write_edgelist(G_train, train_graph_filename, data=['weight'])\n",
    "    else:\n",
    "        nx.write_edgelist(G_train, train_graph_filename, data=False)\n",
    "\n",
    "    node_num1, edge_num1 = len(G_train.nodes), len(G_train.edges)\n",
    "    print('Training Graph: nodes:', node_num1, 'edges:', edge_num1)\n",
    "    return G, G_train, testing_pos_edges, train_graph_filename\n",
    "\n",
    "\n",
    "def generate_neg_edges(original_graph, testing_edges_num, seed):\n",
    "    L = list(original_graph.nodes())\n",
    "\n",
    "    # create a complete graph\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(L)\n",
    "    G.add_edges_from(itertools.combinations(L, 2))\n",
    "    # remove original edges\n",
    "    G.remove_edges_from(original_graph.edges())\n",
    "    random.seed(seed)\n",
    "    neg_edges = random.sample(G.edges, testing_edges_num)\n",
    "    return neg_edges\n",
    "\n",
    "\n",
    "def load_embedding(embedding_file_name, node_list=None):\n",
    "    with open(embedding_file_name) as f:\n",
    "        node_num, emb_size = f.readline().split()\n",
    "        print('Nodes with embedding: %s'%node_num)\n",
    "        embedding_look_up = {}\n",
    "        if node_list:\n",
    "            for line in f:\n",
    "                vec = line.strip().split()\n",
    "                node_id = vec[0]\n",
    "                if (node_id in node_list):\n",
    "                    emb = [float(x) for x in vec[1:]]\n",
    "                    emb = emb / np.linalg.norm(emb)\n",
    "                    emb[np.isnan(emb)] = 0\n",
    "                    embedding_look_up[node_id] = np.array(emb)\n",
    "\n",
    "            # if len(node_list) != len(embedding_look_up):\n",
    "            #     diff_nodes=set(node_list).difference(set(embedding_look_up.keys()))\n",
    "            #     for node in diff_nodes:\n",
    "            #         emb = np.random.random((int(emb_size)))\n",
    "            #         emb = emb / np.linalg.norm(emb)\n",
    "            #         emb[np.isnan(emb)] = 0\n",
    "            #         embedding_look_up[node] = np.array(emb)\n",
    "\n",
    "            assert len(node_list) == len(embedding_look_up)\n",
    "        else:\n",
    "            for line in f:\n",
    "                vec = line.strip().split()\n",
    "                node_id = vec[0]\n",
    "                embeddings = vec[1:]\n",
    "                emb = [float(x) for x in embeddings]\n",
    "                emb = emb / np.linalg.norm(emb)\n",
    "                emb[np.isnan(emb)] = 0\n",
    "                embedding_look_up[node_id] = list(emb)\n",
    "            assert int(node_num) == len(embedding_look_up)\n",
    "        f.close()\n",
    "        return embedding_look_up\n",
    "\n",
    "\n",
    "def read_node_labels(filename):\n",
    "    fin = open(filename, 'r')\n",
    "    node_list = []\n",
    "    labels = []\n",
    "    while 1:\n",
    "        l = fin.readline()\n",
    "        if l == '':\n",
    "            break\n",
    "        vec = l.strip().split()\n",
    "        node_list.append(vec[0])\n",
    "        labels.append(vec[1:])\n",
    "    fin.close()\n",
    "    print('Nodes with labels: %s'%len(node_list))\n",
    "    return node_list, labels\n",
    "\n",
    "\n",
    "def split_train_test_classify(embedding_look_up, X, Y, seed, testing_ratio=0.2):\n",
    "    state = np.random.get_state()\n",
    "    training_ratio = 1 - testing_ratio\n",
    "    training_size = int(training_ratio * len(X))\n",
    "    np.random.seed(seed)\n",
    "    shuffle_indices = np.random.permutation(np.arange(len(X)))\n",
    "    X_train = [embedding_look_up[X[shuffle_indices[i]]] for i in range(training_size)]\n",
    "    Y_train = [Y[shuffle_indices[i]] for i in range(training_size)]\n",
    "    X_test = [embedding_look_up[X[shuffle_indices[i]]] for i in range(training_size, len(X))]\n",
    "    Y_test = [Y[shuffle_indices[i]] for i in range(training_size, len(X))]\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    Y_test = np.array(Y_test)\n",
    "\n",
    "    np.random.set_state(state)\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "\n",
    "def get_y_pred(y_test, y_pred_prob):\n",
    "    y_pred = np.zeros(y_pred_prob.shape)\n",
    "    sort_index = np.flip(np.argsort(y_pred_prob, axis=1), 1)\n",
    "    for i in range(y_test.shape[0]):\n",
    "        num = np.sum(y_test[i])\n",
    "        for j in range(num):\n",
    "            y_pred[i][sort_index[i][j]] = 1\n",
    "    return y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
