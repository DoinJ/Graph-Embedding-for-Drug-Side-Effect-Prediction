{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d57f934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from embed_train.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anaconda\\envs\\tensorflow_gpu\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from node2vec.ipynb\n",
      "importing Jupyter notebook from walker.ipynb\n",
      "importing Jupyter notebook from utils.ipynb\n",
      "importing Jupyter notebook from graph.ipynb\n",
      "importing Jupyter notebook from evaluation.ipynb\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import getpass\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser\n",
    "import Ipynb_importer\n",
    "import numpy as np\n",
    "\n",
    "from embed_train import embedding_training, load_embedding, read_node_labels, split_train_test_graph\n",
    "from evaluation import LinkPrediction      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c89d8581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################################################\n",
      "Embedding Method: node2vec, Evaluation Task: link-prediction\n",
      "######################################################################\n",
      "Original Graph: nodes: 645 edges: 63449\n",
      "Training Graph: nodes: 645 edges: 57105\n",
      "Loading training graph for learning embedding...\n",
      "Graph Loaded...\n",
      "Preprocess transition probs...\n",
      "Begin random walk...\n",
      "Walk finished...\n",
      "Learning representation...\n",
      "Saving embeddings...\n",
      "Embedding Learning Time: 171.64 s\n",
      "Nodes with embedding: 645\n",
      "Begin evaluation...\n",
      "######### Link Prediction Performance #########\n",
      "AUC-ROC: 0.851, AUC-PR: 0.785, Accuracy: 0.681, F1: 0.755\n",
      "##################################################\n",
      "Prediction Task Time: 7.10 s\n"
     ]
    }
   ],
   "source": [
    "# choose the type of model and perform the link prediction task\n",
    "def parse_args():\n",
    "    parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter,\n",
    "                            conflict_handler='resolve')\n",
    "    parser.add_argument('--input', required=True,\n",
    "                        help='Input graph file. Only accepted edgelist format.')\n",
    "    parser.add_argument('--output',\n",
    "                        help='Output graph embedding file', required=True)\n",
    "    parser.add_argument('--task', choices=[\n",
    "        'none',\n",
    "        'link-prediction'], default='none',\n",
    "                        help='Choose to evaluate the embedding quality based on a specific prediction task. '\n",
    "                             'None represents no evaluation, and only run for training embedding.')\n",
    "    parser.add_argument('--testingratio', default=0.1, type=float,\n",
    "                        help='Testing set ratio for prediction tasks.'\n",
    "                             'In link prediction, it splits all the known edges. ')\n",
    "    parser.add_argument('--number-walks', default=32, type=int,\n",
    "                        help='Number of random walks to start at each node. '\n",
    "                             'Only for random walk-based methods: DeepWalk, node2vec, struc2vec')\n",
    "    parser.add_argument('--walk-length', default=64, type=int,\n",
    "                        help='Length of the random walk started at each node. '\n",
    "                             'Only for random walk-based methods: DeepWalk, node2vec, struc2vec')\n",
    "    parser.add_argument('--workers', default=8, type=int,\n",
    "                        help='Number of parallel processes. '\n",
    "                             'Only for random walk-based methods: DeepWalk, node2vec, struc2vec')\n",
    "    parser.add_argument('--dimensions', default=100, type=int,\n",
    "                        help='the dimensions of embedding for each node.')\n",
    "    parser.add_argument('--window-size', default=10, type=int,\n",
    "                        help='Window size of word2vec model. '\n",
    "                             'Only for random walk-based methods: DeepWalk, node2vec, struc2vec')\n",
    "    parser.add_argument('--p', default=1.0, type=float,\n",
    "                        help='p is a hyper-parameter for node2vec, '\n",
    "                             'and it controls how fast the walk explores.')\n",
    "    parser.add_argument('--q', default=1.0, type=float,\n",
    "                        help='q is a hyper-parameter for node2vec, '\n",
    "                             'and it controls how fast the walk leaves the neighborhood of starting node.')\n",
    "    parser.add_argument('--method', required=True, choices=[\n",
    "        'DeepWalk',\n",
    "        'node2vec',\n",
    "    ], help='The embedding learning method')\n",
    "\n",
    "    parser.add_argument('--weighted', type=bool, default=False,\n",
    "                        help='Treat graph as weighted')\n",
    "    parser.add_argument('--directed', type=bool, default=False,\n",
    "                        help='Treat graph as directed')\n",
    "    parser.add_argument('--eval-result-file', help='save evaluation performance')\n",
    "    parser.add_argument('--seed',default=0, type=int,  help='seed value')\n",
    "    args = parser.parse_args(args=['--input','.../cxj973/data/drug_combinations.txt',\n",
    "                                   '--output','.../node2vec_embeddings3.txt',\n",
    "                                   '--task','link-prediction',\n",
    "                                   '--method','node2vec',\n",
    "                                   '--eval-result-file','.../results.txt'])\n",
    "    # replace \"...\" in the arguments with your own path of the drug_combination file and your expected output path\n",
    "    return args  \n",
    "\n",
    "def main(args):\n",
    "    print('#' * 70)\n",
    "    print('Embedding Method: %s, Evaluation Task: %s' % (args.method, args.task))\n",
    "    print('#' * 70)\n",
    "\n",
    "    if args.task == 'link-prediction':\n",
    "        G, G_train, testing_pos_edges, train_graph_filename = split_train_test_graph(args.input, args.seed, weighted=args.weighted)\n",
    "        time1 = time.time()\n",
    "        embedding_training(args, train_graph_filename)\n",
    "        embed_train_time = time.time() - time1\n",
    "        print('Embedding Learning Time: %.2f s' % embed_train_time)\n",
    "        embedding_look_up = load_embedding(args.output)\n",
    "        time1 = time.time()\n",
    "        print('Begin evaluation...')\n",
    "        result = LinkPrediction(embedding_look_up, G, G_train, testing_pos_edges,args.seed)\n",
    "        eval_time = time.time() - time1\n",
    "        print('Prediction Task Time: %.2f s' % eval_time)\n",
    "        os.remove(train_graph_filename)\n",
    "    else:\n",
    "        train_graph_filename = args.input\n",
    "        time1 = time.time()\n",
    "        embedding_training(args, train_graph_filename)\n",
    "        embed_train_time = time.time() - time1\n",
    "        print('Embedding Learning Time: %.2f s' % embed_train_time)\n",
    "\n",
    "    if args.eval_result_file and result:\n",
    "        _results = dict(\n",
    "            input=args.input,\n",
    "            task=args.task,\n",
    "            method=args.method,\n",
    "            dimension=args.dimensions,\n",
    "            user=getpass.getuser(),\n",
    "            date=datetime.datetime.now().strftime('%Y-%m-%d-%H%M%S'),\n",
    "            seed=args.seed,\n",
    "        )\n",
    "\n",
    "        if args.task == 'link-prediction':\n",
    "            auc_roc, auc_pr, accuracy, f1 = result\n",
    "            _results['results'] = dict(\n",
    "                auc_roc=auc_roc,\n",
    "                auc_pr=auc_pr,\n",
    "                accuracy=accuracy,\n",
    "                f1=f1,\n",
    "            )\n",
    "        else:\n",
    "            accuracy, f1_micro, f1_macro = result\n",
    "            _results['results'] = dict(\n",
    "                accuracy=accuracy,\n",
    "                f1_micro=f1_micro,\n",
    "                f1_macro=f1_macro,\n",
    "            )\n",
    "\n",
    "        with open(args.eval_result_file, 'a+') as wf:\n",
    "            print(json.dumps(_results, sort_keys=True), file=wf)\n",
    "\n",
    "\n",
    "def more_main():\n",
    "    args = parse_args()\n",
    "    seed = args.seed\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    main(parse_args())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    more_main() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
