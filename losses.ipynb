{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def reduce_loss(loss_vector, reduction_type):\n",
    "    \"\"\" Reduce loss vector\n",
    "    Parameters\n",
    "    ----------\n",
    "    loss_vector\n",
    "    reduction_type\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    if reduction_type == \"sum\":\n",
    "        return tf.reduce_sum(loss_vector)\n",
    "    elif reduction_type == \"avg\" or reduction_type == \"average\":\n",
    "        return tf.reduce_mean(loss_vector)\n",
    "    elif reduction_type == \"none\" or reduction_type == \"raw\":\n",
    "        return loss_vector\n",
    "    else:\n",
    "        raise ValueError(\"Unknown reduction type (%s). options are ['sum', 'avg', 'none']\" % reduction_type)\n",
    "\n",
    "\n",
    "def pointwise_logistic_loss(scores, targets, reduction_type=\"sum\", *args, **kwargs):\n",
    "    \"\"\" Negative log-likelihood loss.\n",
    "    Parameters\n",
    "    ----------\n",
    "    scores : tf.tensor\n",
    "        Tensor containing (N,) scores one for each example.\n",
    "    targets : tf.tensor\n",
    "        Tensor containing (N,) labels one for each example.\n",
    "    reduction_type: str\n",
    "        loss reduction technique. options ['sum', 'avg']\n",
    "    args: list\n",
    "            Non-key arguments\n",
    "    kwargs: dict\n",
    "        Key arguments\n",
    "    Returns\n",
    "    -------\n",
    "    tf.float32\n",
    "        Loss value.\n",
    "    \"\"\"\n",
    "    logistic_losses = tf.nn.softplus(-targets * scores)\n",
    "    return reduce_loss(logistic_losses, reduction_type)\n",
    "\n",
    "\n",
    "def pairwise_logistic_loss(positive_scores, negative_scores, reduction_type=\"sum\", *args, **kwargs):\n",
    "    \"\"\" Negative log-likelihood loss.\n",
    "    Parameters\n",
    "    ----------\n",
    "    positive_scores : tf.tensor\n",
    "        Tensor containing (N,) positive scores one for each example.\n",
    "    negative_scores : tf.tensor\n",
    "        Tensor containing (N,) negative scores one for each example.\n",
    "    reduction_type: str\n",
    "        loss reduction technique. options ['sum', 'avg']\n",
    "    args: list\n",
    "            Non-key arguments\n",
    "    kwargs: dict\n",
    "        Key arguments\n",
    "    Returns\n",
    "    -------\n",
    "    tf.float32\n",
    "        Loss value.\n",
    "    \"\"\"\n",
    "    logistic_losses = tf.nn.softplus(negative_scores - positive_scores)\n",
    "    return reduce_loss(logistic_losses, reduction_type)\n",
    "\n",
    "\n",
    "def compute_kge_loss(scores, loss_type, reduction_type=\"sum\", *args, **kwargs):\n",
    "    \"\"\" Compute loss function.\n",
    "    Parameters\n",
    "    ----------\n",
    "    scores: tf.tensor\n",
    "        (N,) tensorflow tensor with all batch triples score.\n",
    "    loss_type: str\n",
    "        loss function type\n",
    "    reduction_type: str\n",
    "        loss reduction technique. options ['sum', 'avg']\n",
    "    args: list\n",
    "        Non-key arguments\n",
    "    kwargs: dict\n",
    "        Key arguments\n",
    "    Returns\n",
    "    -------\n",
    "    tf.float32\n",
    "        Model loss.\n",
    "    \"\"\"\n",
    "    positive_scores, negative_scores = tf.split(value=scores, num_or_size_splits=2, axis=0)\n",
    "    targets = tf.concat((tf.ones(tf.shape(positive_scores)), -1 * tf.ones(tf.shape(negative_scores))), axis=0)\n",
    "\n",
    "    if loss_type == \"pt_sel\" or loss_type == \"pointwise_square_error_loss\" or loss_type == \"pt_se\":\n",
    "        targets = (targets + 1) / 2\n",
    "        loss = pointwise_square_error_loss(scores, targets, reduction_type=reduction_type, *args, **kwargs)\n",
    "\n",
    "    elif loss_type == \"pt_log\" or loss_type == \"pointwise_log_loss\":\n",
    "        loss = pointwise_logistic_loss(scores, targets, *args, **kwargs)\n",
    "\n",
    "    elif loss_type == \"pt_hinge\" or loss_type == \"pointwise_hinge_loss\":\n",
    "        loss = pointwise_hinge_loss(scores, targets, *args, **kwargs)\n",
    "\n",
    "    elif loss_type == \"pr_hinge\" or loss_type == \"pairwise_hinge_loss\":\n",
    "        loss = pairwise_hinge_loss(positive_scores, negative_scores, *args, **kwargs)\n",
    "\n",
    "    elif loss_type == \"pr_log\" or loss_type == \"pairwise_logistic_loss\":\n",
    "        loss = pairwise_logistic_loss(positive_scores, negative_scores, *args, **kwargs)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown loss type (%s)\" % loss_type)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def mc_softmax_negative_log_loss(score_matrix, true_indices, reduction_type=\"sum\", *args, **kwargs):\n",
    "    \"\"\" Compute the softmax negative-log loss for a score matrix of a data batch\n",
    "    Parameters\n",
    "    ----------\n",
    "    score_matrix : tf.tensor\n",
    "        data scores matrix of size [N, M] where N is the data size and M is the number of scores per instance\n",
    "    true_indices : tf.tensor\n",
    "        indices of the true triples of the scoring matrix where each index represent the index of the only true\n",
    "        instance of a matrix row of scores.\n",
    "    reduction_type: str\n",
    "        loss reduction technique. options ['sum', 'avg']\n",
    "    args: list\n",
    "        Non-key arguments\n",
    "    kwargs: dict\n",
    "        Key arguments\n",
    "    Returns\n",
    "    -------\n",
    "    tf.float\n",
    "        the loss value\n",
    "    \"\"\"\n",
    "    # apply softmax on scores\n",
    "    score_matrix = tf.nn.softmax(score_matrix)\n",
    "\n",
    "    # clip score values to fit the neg-log loss constraints\n",
    "    eps = 1e-15\n",
    "    score_matrix = tf.clip_by_value(score_matrix, eps, 1 - eps)\n",
    "\n",
    "    # get positive scores\n",
    "    rows = tf.range(tf.shape(score_matrix)[0])\n",
    "    data_pos_idx = tf.transpose(tf.stack([rows, true_indices]))\n",
    "    data_pos_scores = tf.gather_nd(score_matrix, data_pos_idx)\n",
    "\n",
    "    # compute the loss\n",
    "    data_loss = -tf.log(data_pos_scores)\n",
    "    return reduce_loss(data_loss, reduction_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
